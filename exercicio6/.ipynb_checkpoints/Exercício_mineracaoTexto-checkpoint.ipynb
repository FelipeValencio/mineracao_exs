{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista 7 - Exercício de Mineração de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 1 \n",
    "\n",
    "Use o dataset \"tweets_trump.csv\", que contém todos os tweets do D. Trump e faça o que é pedido abaixo.\n",
    "\n",
    "a) Utilizando o texto dos tweets identifique 5 tópicos latentes com o LDA, com um preprocessamento básico -- remoção de urls, remoção de pontuação, stemming e conversão para minúsculo. \n",
    "\n",
    "b) Avalie os tópicos encontrados. Algum preprocessamento a mais poderia ser útil para a produção de um melhor resultado?\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T19:20:47.104514Z",
     "start_time": "2024-05-19T19:20:47.102379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T19:21:08.271694Z",
     "start_time": "2024-05-19T19:21:08.165742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importar arquivo\n",
    "dfTweets= pd.read_csv(\"tweets_trump.csv\")\n",
    "tweets = dfTweets['text']\n",
    "tweets[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Republicans and Democrats have both created our economic problems.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T19:39:53.393319Z",
     "start_time": "2024-05-19T19:39:48.861986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remover URLS\n",
    "url_pattern = r'http[s]?://\\S+'\n",
    "tweets = tweets[~tweets.str.match(url_pattern)]\n",
    "tweets = tweets.apply(lambda x: re.sub(url_pattern, '', x))\n",
    "\n",
    "# Converter para minúsculo\n",
    "tweets = tweets.str.lower()\n",
    "\n",
    "# remover pontuação\n",
    "PONTUACAO = string.punctuation\n",
    "def remove_pontuacao(text):\n",
    "    return text.translate(str.maketrans('', '', PONTUACAO))\n",
    "\n",
    "tweets = tweets.apply(lambda text: remove_pontuacao(text))\n",
    "\n",
    "# Remover stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "tweets = tweets.apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "tweets = tweets.apply(lambda text: stem_words(text))\n",
    "\n",
    "tweets"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 republican democrat creat econom problem\n",
       "1        thrill back great citi charlott north carolina...\n",
       "2        rt cbsherridg read letter surveil court obtain...\n",
       "3        unsolicit mail ballot scam major threat democr...\n",
       "4        rt mzhemingway friendli tell event comey appar...\n",
       "                               ...                        \n",
       "56566    rt randpaul don’t know joebiden think continu ...\n",
       "56567    rt elisestefanik presid realdonaldtrump excel ...\n",
       "56568    rt teamtrump live presidenti debat debates2020...\n",
       "56569    sign order support worker delphi corpor make s...\n",
       "56570    suburban women want safeti amp secur joe biden...\n",
       "Name: text, Length: 55265, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T19:40:22.147108Z",
     "start_time": "2024-05-19T19:39:56.870611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Tópicos\n",
    "dataset_prep = [d.split() for d in tweets]\n",
    "dictionary_prep = Dictionary(dataset_prep)\n",
    "corpus_prep = [dictionary_prep.doc2bow(doc) for doc in dataset_prep]\n",
    "\n",
    "model_prep = LdaModel(corpus=corpus_prep, id2word=dictionary_prep, num_topics=5, iterations=100, passes=5,random_state=1)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T19:40:24.855192Z",
     "start_time": "2024-05-19T19:40:24.850974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in model_prep.show_topics(num_topics=5, num_words=6, log=False):\n",
    "    print(i)\n",
    "    print('---')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.062*\"rt\" + 0.036*\"realdonaldtrump\" + 0.036*\"presid\" + 0.021*\"trump\" + 0.011*\"impeach\" + 0.010*\"hillari\"')\n",
      "---\n",
      "(1, '0.017*\"border\" + 0.016*\"us\" + 0.015*\"amp\" + 0.014*\"american\" + 0.013*\"countri\" + 0.011*\"state\"')\n",
      "---\n",
      "(2, '0.044*\"thank\" + 0.031*\"great\" + 0.022*\"trump\" + 0.020*\"realdonaldtrump\" + 0.016*\"rt\" + 0.010*\"donald\"')\n",
      "---\n",
      "(3, '0.027*\"great\" + 0.013*\"big\" + 0.012*\"get\" + 0.011*\"go\" + 0.010*\"make\" + 0.010*\"time\"')\n",
      "---\n",
      "(4, '0.020*\"news\" + 0.017*\"fake\" + 0.014*\"media\" + 0.012*\"report\" + 0.011*\"amp\" + 0.009*\"collu\"')\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Use o dataset \"tweets_trump.csv\" e responda:\n",
    "\n",
    "a) Qual o sentimento dos 5 tweets com maior número de retweets?\n",
    "\n",
    "b) Faça uma análise do sentimento geral de todos os tweets. Para isso, visualize a distribuição de polaridade para embasar a sua resposta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
